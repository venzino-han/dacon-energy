{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:00:27.092203Z",
     "start_time": "2021-05-27T13:00:22.725441Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import random\n",
    "random.seed(42)\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "import gc\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import tensorflow_data_validation as tfdv\n",
    "\n",
    "import time\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:00:27.097234Z",
     "start_time": "2021-05-27T13:00:27.094797Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import logging.handlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:00:27.111757Z",
     "start_time": "2021-05-27T13:00:27.099194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFDV version: 0.30.0\n"
     ]
    }
   ],
   "source": [
    "print('TFDV version: {}'.format(tfdv.version.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train / val 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:00:27.353916Z",
     "start_time": "2021-05-27T13:00:27.115479Z"
    }
   },
   "outputs": [],
   "source": [
    "path = './dataset_/energy/energy'\n",
    "train = pd.read_csv(path+'/train.csv', encoding = 'cp949')\n",
    "test = pd.read_csv(path+'/test.csv', encoding = 'cp949')\n",
    "sample_submission = pd.read_csv(path + '/sample_submission.csv')\n",
    "\n",
    "train.columns = ['num','date_time','energy','temp','wind_spd','humid','Precip','sun','non_elec','sunlight']\n",
    "# train.to_csv('train_.csv',encoding='cp949')\n",
    "test.columns = ['num','date_time','temp','wind_spd','humid','Precip','sun','non_elec','sunlight']\n",
    "# test.to_csv('test_.csv',encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:00:29.620158Z",
     "start_time": "2021-05-27T13:00:29.614708Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:00:30.245968Z",
     "start_time": "2021-05-27T13:00:30.239444Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# def create_sequences(dataset, start, end, time_steps=24):\n",
    "#     dataset.set_index('date_time',inplace=True)\n",
    "    \n",
    "#     if 'energy' in dataset:    \n",
    "#         data_set = dataset.iloc[int(start*len(dataset)) : int(end*len(dataset)), :]\n",
    "\n",
    "#         y_set = dataset[['energy']]\n",
    "#         x_set = dataset.drop('energy', axis=1)\n",
    "\n",
    "#         x_ = []\n",
    "#         y_ = []\n",
    "#         for i in range(len(y_set) - time_steps + 1):\n",
    "#             x_.append(x_set.iloc[i : (i + time_steps),:])\n",
    "#             y_.append(y_set.iloc[i : (i + time_steps),:])\n",
    "            \n",
    "#         return np.stack(x_), np.stack(y_)\n",
    "        \n",
    "#     # test_set 에서 energy가 없는 경우\n",
    "#     else:\n",
    "#         data_set = dataset.iloc[int(start*len(dataset)) : int(end*len(dataset)), :]\n",
    "#         for i in range(len(y_set) - time_steps + 1):\n",
    "#             x_.append(x_set.iloc[i : (i + time_steps),:])\n",
    "\n",
    "#         return np.stack(x_), _\n",
    "\n",
    "\n",
    "# # dataset\n",
    "# def get_each_id_set(dataset, start, end, steps=24):\n",
    "#     data_dic = {}\n",
    "\n",
    "#     x_lst = []\n",
    "#     y_lst = []\n",
    "#     for i in range(1,61):\n",
    "#         x_, y_ = create_sequences(dataset[dataset.num==i], start, end, steps)\n",
    "#         x_lst.append(x_)\n",
    "#         y_lst.append(y_)\n",
    "\n",
    "#     return x_lst, y_lst\n",
    "\n",
    "# class CustomDataset(Dataset):    \n",
    "#     def __init__(self, \n",
    "#                  dataset,\n",
    "#                  start = 0,\n",
    "#                  end = 1,\n",
    "#                  steps = 24\n",
    "#                  ):\n",
    "        \n",
    "#         self.dataset = dataset\n",
    "#         self.steps = steps\n",
    "#         self.start = start\n",
    "#         self.end = end\n",
    "\n",
    "#         self.x, self.y = get_each_id_set(dataset, start, end, steps)\n",
    "    \n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.x)\n",
    "    \n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "        \n",
    "#         return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:00:30.447013Z",
     "start_time": "2021-05-27T13:00:30.389342Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>date_time</th>\n",
       "      <th>energy</th>\n",
       "      <th>temp</th>\n",
       "      <th>wind_spd</th>\n",
       "      <th>humid</th>\n",
       "      <th>Precip</th>\n",
       "      <th>sun</th>\n",
       "      <th>non_elec</th>\n",
       "      <th>sunlight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-06-01 00</td>\n",
       "      <td>8179.056</td>\n",
       "      <td>17.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-06-01 01</td>\n",
       "      <td>8135.640</td>\n",
       "      <td>17.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-06-01 02</td>\n",
       "      <td>8107.128</td>\n",
       "      <td>17.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-06-01 03</td>\n",
       "      <td>8048.808</td>\n",
       "      <td>17.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-06-01 04</td>\n",
       "      <td>8043.624</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122395</th>\n",
       "      <td>60</td>\n",
       "      <td>2020-08-24 19</td>\n",
       "      <td>4114.368</td>\n",
       "      <td>27.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122396</th>\n",
       "      <td>60</td>\n",
       "      <td>2020-08-24 20</td>\n",
       "      <td>3975.696</td>\n",
       "      <td>27.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122397</th>\n",
       "      <td>60</td>\n",
       "      <td>2020-08-24 21</td>\n",
       "      <td>3572.208</td>\n",
       "      <td>27.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122398</th>\n",
       "      <td>60</td>\n",
       "      <td>2020-08-24 22</td>\n",
       "      <td>3299.184</td>\n",
       "      <td>27.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122399</th>\n",
       "      <td>60</td>\n",
       "      <td>2020-08-24 23</td>\n",
       "      <td>3204.576</td>\n",
       "      <td>27.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122400 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        num      date_time    energy  temp  wind_spd  humid  Precip  sun  \\\n",
       "0         1  2020-06-01 00  8179.056  17.6       2.5   92.0     0.8  0.0   \n",
       "1         1  2020-06-01 01  8135.640  17.7       2.9   91.0     0.3  0.0   \n",
       "2         1  2020-06-01 02  8107.128  17.5       3.2   91.0     0.0  0.0   \n",
       "3         1  2020-06-01 03  8048.808  17.1       3.2   91.0     0.0  0.0   \n",
       "4         1  2020-06-01 04  8043.624  17.0       3.3   92.0     0.0  0.0   \n",
       "...     ...            ...       ...   ...       ...    ...     ...  ...   \n",
       "122395   60  2020-08-24 19  4114.368  27.8       2.3   68.0     0.0  0.7   \n",
       "122396   60  2020-08-24 20  3975.696  27.3       1.2   71.0     0.0  0.0   \n",
       "122397   60  2020-08-24 21  3572.208  27.3       1.8   71.0     0.0  0.0   \n",
       "122398   60  2020-08-24 22  3299.184  27.1       1.8   74.0     0.0  0.0   \n",
       "122399   60  2020-08-24 23  3204.576  27.1       2.6   75.0     0.0  0.0   \n",
       "\n",
       "        non_elec  sunlight  \n",
       "0            0.0       0.0  \n",
       "1            0.0       0.0  \n",
       "2            0.0       0.0  \n",
       "3            0.0       0.0  \n",
       "4            0.0       0.0  \n",
       "...          ...       ...  \n",
       "122395       1.0       1.0  \n",
       "122396       1.0       1.0  \n",
       "122397       1.0       1.0  \n",
       "122398       1.0       1.0  \n",
       "122399       1.0       1.0  \n",
       "\n",
       "[122400 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:00:30.574372Z",
     "start_time": "2021-05-27T13:00:30.562074Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_sequences(dataset, start, end):\n",
    "    dataset.set_index('date_time',inplace=True)\n",
    "    data_set = dataset.iloc[int(start*len(dataset)) : int(end*len(dataset)), :]\n",
    "    \n",
    "    return data_set \n",
    "\n",
    "# dataset\n",
    "def get_each_id_set(dataset, num, start, end):\n",
    "    data_dic = {}\n",
    "\n",
    "    x_lst = 0\n",
    "    for i in range(1,num+1):\n",
    "        x_ = create_sequences(dataset[dataset.num==i], start, end)\n",
    "        \n",
    "        if type(x_lst) == type(0):\n",
    "            x_lst = x_\n",
    "            \n",
    "        else:\n",
    "            x_lst = pd.concat([x_lst, x_])\n",
    "\n",
    "            \n",
    "    return x_lst.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:10:21.518839Z",
     "start_time": "2021-05-27T13:10:20.872206Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ = get_each_id_set(train, 60, 0, 0.8)\n",
    "val_ = get_each_id_set(train, 60, 0.8, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:10:21.527810Z",
     "start_time": "2021-05-27T13:10:21.521531Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_group(dataset):\n",
    "    group = dataset[['num', 'energy', 'temp', 'wind_spd', 'humid', 'Precip', 'sun', 'non_elec', 'sunlight']].groupby('num').apply(lambda r: (\n",
    "                r['num'].values,\n",
    "                r['energy'].values,\n",
    "                r['temp'].values,\n",
    "                r['wind_spd'].values,\n",
    "                r['humid'].values,\n",
    "                r['Precip'].values,\n",
    "                r['sun'].values,\n",
    "                r['non_elec'].values,\n",
    "                r['sunlight'].values))\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:10:22.327203Z",
     "start_time": "2021-05-27T13:10:22.217987Z"
    }
   },
   "outputs": [],
   "source": [
    "train_group = get_group(train_)\n",
    "val_group = get_group(val_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:10:22.754909Z",
     "start_time": "2021-05-27T13:10:22.748092Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# def create_sequences(dataset, batch_size, start, end, time_steps=24):\n",
    "#     dataset.set_index('date_time',inplace=True)\n",
    "#     data_set = dataset.iloc[int(start*len(dataset)) : int(end*len(dataset)), :]\n",
    "\n",
    "#     num = []\n",
    "#     energy = []\n",
    "#     temp = []\n",
    "#     wind_spd = []\n",
    "#     humid = []\n",
    "#     precip = []\n",
    "#     sun = []\n",
    "#     non_elec = []\n",
    "#     sunlight = []\n",
    "\n",
    "#     if 'energy' in data_set:\n",
    "#         for i in range(len(y_set) - time_steps + 1):\n",
    "#             num.append(data_set.num[i : (i + time_steps)].tolist())\n",
    "#             energy.append(data_set.energy[i : (i + time_steps)].tolist())\n",
    "#             temp.append(data_set.temp[i : (i + time_steps)].tolist())\n",
    "#             wind_spd.append(data_set.wind_spd[i : (i + time_steps)].tolist())\n",
    "#             humid.append(data_set.humid[i : (i + time_steps)].tolist())\n",
    "#             precip.append(data_set.precip[i : (i + time_steps)].tolist())\n",
    "#             sun.append(data_set.sun[i : (i + time_steps)].tolist())\n",
    "#             non_elec.append(data_set.non_elec[i : (i + time_steps)].tolist())\n",
    "#             sunlight.append(data_set.sunlight[i : (i + time_steps)].tolist())\n",
    "\n",
    "#     else:\n",
    "#         for i in range(len(y_set) - time_steps + 1):\n",
    "#             num.append(data_set.num[i : (i + time_steps)].tolist())\n",
    "#     #         energy.append(data_set.energy[i : (i + time_steps)].tolist())\n",
    "#             temp.append(data_set.temp[i : (i + time_steps)].tolist())\n",
    "#             wind_spd.append(data_set.wind_spd[i : (i + time_steps)].tolist())\n",
    "#             humid.append(data_set.humid[i : (i + time_steps)].tolist())\n",
    "#             precip.append(data_set.precip[i : (i + time_steps)].tolist())\n",
    "#             sun.append(data_set.sun[i : (i + time_steps)].tolist())\n",
    "#             non_elec.append(data_set.non_elec[i : (i + time_steps)].tolist())\n",
    "#             sunlight.append(data_set.sunlight[i : (i + time_steps)].tolist())\n",
    "        \n",
    "#         return \n",
    "        \n",
    "#     # test_set 에서 energy가 없는 경우\n",
    "#     else:\n",
    "#         data_set = dataset.iloc[int(start*len(dataset)) : int(end*len(dataset)), :]\n",
    "        \n",
    "#         for i in range(len(y_set) - time_steps + 1):\n",
    "#             x_.append(x_set.iloc[i : (i + time_steps),:])\n",
    "\n",
    "#         return x_, _\n",
    "\n",
    "\n",
    "# # dataset\n",
    "# def get_each_id_set(dataset, batch_size, start, end, steps=24):\n",
    "#     data_dic = {}\n",
    "\n",
    "#     x_lst = []\n",
    "#     y_lst = []\n",
    "#     for i in range(1,61):\n",
    "#         x_, y_ = create_sequences(dataset[dataset.num==i], batch_size, start, end, steps)\n",
    "#         x_lst.extend(x_)\n",
    "#         y_lst.extend(y_)\n",
    "\n",
    "#     return np.stack(x_lst), np.stack(y_lst)\n",
    "\n",
    "# class CustomDataset(Dataset):    \n",
    "#     def __init__(self, \n",
    "#                  dataset,\n",
    "#                  batch_size,\n",
    "#                  start = 0,\n",
    "#                  end = 1,\n",
    "#                  steps = 24\n",
    "#                  ):\n",
    "        \n",
    "#         self.dataset = dataset\n",
    "#         self.batch_size = batch_size\n",
    "#         self.steps = steps\n",
    "#         self.start = start\n",
    "#         self.end = end\n",
    "\n",
    "#         self.x, self.y = get_each_id_set(dataset, batch_size, start, end, steps)\n",
    "    \n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.x)\n",
    "    \n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "        \n",
    "#         return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:10:24.118218Z",
     "start_time": "2021-05-27T13:10:23.248631Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dacon_Dataset(Dataset):\n",
    "    def __init__(self, dataset, time_steps = 24, test = False):\n",
    "        self.dataset = dataset\n",
    "        self.time_steps = time_steps\n",
    "        self.test = test\n",
    "        \n",
    "        self.samples = {}\n",
    "        self.user_ids = []\n",
    "        \n",
    "        for user_id in dataset.index:\n",
    "            if self.test == True:\n",
    "                num, temp, wind_spd, humid, precip, sun, non_elec, sunlight = dataset[user_id]\n",
    "\n",
    "                if len(num) > self.time_steps:\n",
    "                    total_steps = len(num)\n",
    "\n",
    "                    for seq in range(len(num) - self.time_steps + 1):\n",
    "                        self.user_ids.append(f\"{user_id}_{seq}\")\n",
    "\n",
    "                        start = seq\n",
    "                        end = seq + self.time_steps\n",
    "\n",
    "                        self.samples[f\"{user_id}_{seq}\"] = (num[start:end], \n",
    "#                                                             energy[start:end], \n",
    "                                                            temp[start:end], \n",
    "                                                            wind_spd[start:end], \n",
    "                                                            humid[start:end], \n",
    "                                                            precip[start:end],\n",
    "                                                            sun[start:end],\n",
    "                                                            non_elec[start:end],\n",
    "                                                            sunlight[start:end])\n",
    "\n",
    "\n",
    "            else:\n",
    "                num, energy, temp, wind_spd, humid, precip, sun, non_elec, sunlight = dataset[user_id]\n",
    "\n",
    "                if len(num) > self.time_steps:\n",
    "                    total_steps = len(num)\n",
    "\n",
    "                    for seq in range(len(num) - self.time_steps + 1):\n",
    "                        self.user_ids.append(f\"{user_id}_{seq}\")\n",
    "\n",
    "                        start = seq\n",
    "                        end = seq + self.time_steps\n",
    "\n",
    "                        self.samples[f\"{user_id}_{seq}\"] = (num[start:end], \n",
    "                                                            energy[start:end], \n",
    "                                                            temp[start:end], \n",
    "                                                            wind_spd[start:end], \n",
    "                                                            humid[start:end], \n",
    "                                                            precip[start:end],\n",
    "                                                            sun[start:end],\n",
    "                                                            non_elec[start:end],\n",
    "                                                            sunlight[start:end])\n",
    "\n",
    "\n",
    "                else:\n",
    "                    user_id = str(user_id)\n",
    "                    self.user_ids.append(user_id)\n",
    "                    self.samples[user_id] = (num, \n",
    "                                             energy, \n",
    "                                             temp, \n",
    "                                             wind_spd, \n",
    "                                             humid, \n",
    "                                             precip, \n",
    "                                             sun, \n",
    "                                             non_elec, \n",
    "                                             sunlight)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user_ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        user_id = self.user_ids[index]\n",
    "        if self.test == True:\n",
    "            \n",
    "            num_, temp_, wind_spd_, humid_, precip_, sun_, non_elec_, sunlight_ = self.samples[user_id]\n",
    "            seq_len = len(num_)\n",
    "\n",
    "            ## for zero padding\n",
    "            num_ = num_ + 1\n",
    "#             energy_ = energy_*1000 \n",
    "            temp_ = temp_*10 + 1\n",
    "            wind_spd_ = wind_spd_*10 + 1\n",
    "            humid_ = humid_*10 + 1\n",
    "            precip_ = precip_* 10 + 1\n",
    "            sun_ = sun_ * 10 + 1\n",
    "            non_elec_ = non_elec_ + 1\n",
    "            sunlight_ = sunlight_ + 1 \n",
    "\n",
    "            num = np.zeros(self.time_steps, dtype=int)\n",
    "#             energy = np.zeros(self.time_steps, dtype=float)\n",
    "            temp = np.zeros(self.time_steps, dtype=int)\n",
    "            wind_spd = np.zeros(self.time_steps, dtype=int)\n",
    "            humid = np.zeros(self.time_steps, dtype=int)\n",
    "            precip = np.zeros(self.time_steps, dtype=int)\n",
    "            sun = np.zeros(self.time_steps, dtype=int)\n",
    "            non_elec = np.zeros(self.time_steps, dtype=int)\n",
    "            sunlight = np.zeros(self.time_steps, dtype=int)\n",
    "\n",
    "            num[:] = num_\n",
    "#             energy[:] = energy_\n",
    "            temp[:] = temp_\n",
    "            wind_spd[:] = wind_spd_\n",
    "            humid[:] = humid_\n",
    "            precip[:] = precip_\n",
    "            sun[:] = sun_\n",
    "            non_elec[:] = non_elec_\n",
    "            sunlight[:] = sunlight_\n",
    "\n",
    "            num = num[1:]\n",
    "#             energy = energy[1:]\n",
    "            temp = temp[1:]\n",
    "            wind_spd = wind_spd[1:]\n",
    "            humid = humid[1:]\n",
    "            precip = precip[1:]\n",
    "            sun = sun[1:]\n",
    "            non_elec = non_elec[1:]\n",
    "            sunlight = sunlight[1:]\n",
    "\n",
    "            return num, temp, wind_spd, humid, precip, sun, non_elec, sunlight\n",
    "        \n",
    "        \n",
    "        else:\n",
    "            num_, energy_, temp_, wind_spd_, humid_, precip_, sun_, non_elec_, sunlight_ = self.samples[user_id]\n",
    "            seq_len = len(num_)\n",
    "\n",
    "            ## for zero padding\n",
    "\n",
    "            energy_ = energy_\n",
    "            temp_ = temp_*10 +1\n",
    "            wind_spd_ = wind_spd_*10 +1\n",
    "            humid_ = humid_*10 + 1\n",
    "            precip_ = precip_* 10 + 1\n",
    "            sun_ = sun_ * 10 + 1\n",
    "            non_elec_ = non_elec_ + 1\n",
    "            sunlight_ = sunlight_ + 1 \n",
    "\n",
    "            num = np.zeros(self.time_steps, dtype=int)\n",
    "            energy = np.zeros(self.time_steps, dtype=float)\n",
    "            temp = np.zeros(self.time_steps, dtype=int)\n",
    "            wind_spd = np.zeros(self.time_steps, dtype=int)\n",
    "            humid = np.zeros(self.time_steps, dtype=int)\n",
    "            precip = np.zeros(self.time_steps, dtype=int)\n",
    "            sun = np.zeros(self.time_steps, dtype=int)\n",
    "            non_elec = np.zeros(self.time_steps, dtype=int)\n",
    "            sunlight = np.zeros(self.time_steps, dtype=int)\n",
    "\n",
    "            num[:] = num_\n",
    "            energy[:] = energy_\n",
    "            temp[:] = temp_\n",
    "            wind_spd[:] = wind_spd_\n",
    "            humid[:] = humid_\n",
    "            precip[:] = precip_\n",
    "            sun[:] = sun_\n",
    "            non_elec[:] = non_elec_\n",
    "            sunlight[:] = sunlight_\n",
    "\n",
    "            num = num[1:]\n",
    "            energy = energy[1:]\n",
    "            temp = temp[1:]\n",
    "            wind_spd = wind_spd[1:]\n",
    "            humid = humid[1:]\n",
    "            precip = precip[1:]\n",
    "            sun = sun[1:]\n",
    "            non_elec = non_elec[1:]\n",
    "            sunlight = sunlight[1:]\n",
    "\n",
    "            return num, energy, temp, wind_spd, humid, precip, sun, non_elec, sunlight\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:10:24.688518Z",
     "start_time": "2021-05-27T13:10:24.120623Z"
    }
   },
   "outputs": [],
   "source": [
    "train_set = Dacon_Dataset(train_group,24,False)\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=False)\n",
    "\n",
    "val_set = Dacon_Dataset(val_group,24,False)\n",
    "val_loader = DataLoader(val_set, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:10:24.712612Z",
     "start_time": "2021-05-27T13:10:24.691103Z"
    }
   },
   "outputs": [],
   "source": [
    "class FFN(nn.Module):\n",
    "    def __init__(self, state_size=200, dropout=0.2):\n",
    "        super(FFN, self).__init__()\n",
    "        self.state_size = state_size\n",
    "\n",
    "        self.lr1 = nn.Linear(state_size, state_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lr2 = nn.Linear(state_size, state_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lr1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.lr2(x)\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "def future_mask(seq_length):\n",
    "    future_mask = np.triu(np.ones((seq_length, seq_length)), k=1).astype('bool')\n",
    "    return torch.from_numpy(future_mask)\n",
    "\n",
    "\n",
    "class Energy_Model(nn.Module):\n",
    "    def __init__(self, \n",
    "                 preprocessed_dataset, \n",
    "                 time_steps=24, \n",
    "                 n_head = 8, \n",
    "                 embed_dim=128,\n",
    "                 num_encoding_layers=6,\n",
    "                 num_decoding_layers=6,\n",
    "                 dropout=0.2):\n",
    "        super(Energy_Model, self).__init__()\n",
    "        \n",
    "        self.preprocessed_dataset = preprocessed_dataset\n",
    "        self.time_steps = time_steps\n",
    "        self.n_head = n_head\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_encoding_layers = num_encoding_layers\n",
    "        self.num_decoding_layers = num_decoding_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        \n",
    "        \n",
    "        self.pos_embedding= nn.Embedding(self.time_steps+1, self.embed_dim) ## position\n",
    "        \n",
    "        \n",
    "        self.num_embedding = nn.Embedding(max(self.preprocessed_dataset['num'])+1, self.embed_dim) ## 건물(?)번호\n",
    "        self.temp_embedding = nn.Embedding(max(self.preprocessed_dataset['temp'])+1, self.embed_dim) ## 온도\n",
    "        self.wind_spd_embedding = nn.Embedding(max(self.preprocessed_dataset['wind_spd'])+1, self.embed_dim) ## 풍속\n",
    "        self.humid_embedding = nn.Embedding(max(self.preprocessed_dataset['humid'])+1, self.embed_dim) ## 습도\n",
    "        self.precip_embedding = nn.Embedding(max(self.preprocessed_dataset['Precip'])+1, self.embed_dim) ## 강수량\n",
    "        self.sun_embedding = nn.Embedding(max(self.preprocessed_dataset['sun'])+1, self.embed_dim) ## 일조\n",
    "        self.non_elec_embedding = nn.Embedding(2+1, self.embed_dim) ## 비전기식 유/무\n",
    "        self.sunlight_embedding = nn.Embedding(2+1, self.embed_dim) ## 태양광 유/무\n",
    "\n",
    "        \n",
    "        self.transformer = nn.Transformer(nhead=self.n_head, d_model = self.embed_dim, num_encoder_layers= self.num_encoding_layers, num_decoder_layers= self.num_decoding_layers, dropout = self.dropout)\n",
    "\n",
    "        self.dropout = nn.Dropout(self.dropout)\n",
    "        self.layer_normal = nn.LayerNorm(self.embed_dim) \n",
    "        self.ffn = FFN(self.embed_dim)\n",
    "        self.pred = nn.Linear(self.embed_dim, 1)\n",
    "\n",
    "    def forward(self, num_, temp_, wind_spd_, humid_, precip_, sun_, non_elec_, sunlight_):\n",
    "\n",
    "        device = num_.device  \n",
    "\n",
    "        ## embedding layer\n",
    "        pos_id = torch.arange(self.time_steps).unsqueeze(0).to(device)\n",
    "        pos_id = self.pos_embedding(pos_id)\n",
    "        \n",
    "        num = self.num_embedding(num_)\n",
    "        temp = self.temp_embedding(temp_)\n",
    "        wind_spd = self.wind_spd_embedding(wind_spd_)\n",
    "        humid = self.humid_embedding(humid_)\n",
    "        precip = self.humid_embedding(precip_)\n",
    "        sun = self.humid_embedding(sun_)\n",
    "        non_elec = self.humid_embedding(non_elec_)\n",
    "        sunlight = self.humid_embedding(sunlight_)\n",
    "\n",
    "        \n",
    "        enc = num + temp + wind_spd + humid + precip + sun + non_elec + sunlight\n",
    "        dec = num + temp + wind_spd + humid + precip + sun + non_elec + sunlight\n",
    "\n",
    "        enc = enc.permute(1, 0, 2) # x: [bs, s_len, embed] => [s_len, bs, embed]\n",
    "        dec = dec.permute(1, 0, 2)\n",
    "        mask = future_mask(enc.size(0)).to(device)\n",
    "\n",
    "        att_output = self.transformer(enc, dec, src_mask=mask, tgt_mask=mask, memory_mask = mask)\n",
    "        att_output = self.layer_normal(att_output)\n",
    "        att_output = att_output.permute(1, 0, 2) # att_output: [s_len, bs, embed] => [bs, s_len, embed]\n",
    "\n",
    "        x = self.ffn(att_output)\n",
    "        x = self.layer_normal(x + att_output)\n",
    "        x = self.pred(x)\n",
    "\n",
    "        return x.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:10:24.738394Z",
     "start_time": "2021-05-27T13:10:24.714745Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocessed_dataset = {}\n",
    "preprocessed_dataset['num'] = (train.num).astype('int32')\n",
    "preprocessed_dataset['temp'] = (train.temp*10+1).astype('int32')\n",
    "preprocessed_dataset['wind_spd'] = (train.wind_spd*10+1).astype('int32')\n",
    "preprocessed_dataset['humid'] = (train.humid*10+1).astype('int32')\n",
    "preprocessed_dataset['Precip'] = (train.Precip*10+1).astype('int32')\n",
    "preprocessed_dataset['sun'] = (train.sun*10+1).astype('int32')\n",
    "preprocessed_dataset['non_elec'] = (train.non_elec +1).astype('int32')\n",
    "preprocessed_dataset['sunlight'] = (train.sunlight +1).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:19:40.448496Z",
     "start_time": "2021-05-27T13:19:39.988478Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSELoss()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "model = Energy_Model(preprocessed_dataset, time_steps=24, n_head=8, embed_dim=256, num_encoding_layers=6,num_decoding_layers=6, dropout=0.2)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "model.to(device)\n",
    "criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:20:13.816466Z",
     "start_time": "2021-05-27T13:20:13.809790Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:20:14.176147Z",
     "start_time": "2021-05-27T13:20:14.167149Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy_Model(\n",
      "  (pos_embedding): Embedding(25, 256)\n",
      "  (num_embedding): Embedding(61, 256)\n",
      "  (temp_embedding): Embedding(365, 256)\n",
      "  (wind_spd_embedding): Embedding(203, 256)\n",
      "  (humid_embedding): Embedding(1002, 256)\n",
      "  (precip_embedding): Embedding(817, 256)\n",
      "  (sun_embedding): Embedding(12, 256)\n",
      "  (non_elec_embedding): Embedding(3, 256)\n",
      "  (sunlight_embedding): Embedding(3, 256)\n",
      "  (transformer): Transformer(\n",
      "    (encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.2, inplace=False)\n",
      "          (dropout2): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.2, inplace=False)\n",
      "          (dropout2): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.2, inplace=False)\n",
      "          (dropout2): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (3): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.2, inplace=False)\n",
      "          (dropout2): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.2, inplace=False)\n",
      "          (dropout2): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (5): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.2, inplace=False)\n",
      "          (dropout2): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.2, inplace=False)\n",
      "          (dropout2): Dropout(p=0.2, inplace=False)\n",
      "          (dropout3): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (1): TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.2, inplace=False)\n",
      "          (dropout2): Dropout(p=0.2, inplace=False)\n",
      "          (dropout3): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (2): TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.2, inplace=False)\n",
      "          (dropout2): Dropout(p=0.2, inplace=False)\n",
      "          (dropout3): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (3): TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.2, inplace=False)\n",
      "          (dropout2): Dropout(p=0.2, inplace=False)\n",
      "          (dropout3): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (4): TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.2, inplace=False)\n",
      "          (dropout2): Dropout(p=0.2, inplace=False)\n",
      "          (dropout3): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (5): TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.2, inplace=False)\n",
      "          (dropout2): Dropout(p=0.2, inplace=False)\n",
      "          (dropout3): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (layer_normal): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  (ffn): FFN(\n",
      "    (lr1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (lr2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (pred): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:20:23.064754Z",
     "start_time": "2021-05-27T13:20:23.028875Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, train_dataloader, val_dataloader, optimizer, criterion, device=\"cuda\"):\n",
    "    model.train()\n",
    "\n",
    "    train_loss = []\n",
    "    num_corrects = 0\n",
    "    num_total = 0\n",
    "    energies = []\n",
    "    outs = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    ## training\n",
    "    for item in train_dataloader:\n",
    "        num = item[0].to(device).long()\n",
    "        temp = item[2].to(device).long()\n",
    "        wind_spd = item[3].to(device).long()\n",
    "        humid = item[4].to(device).long()\n",
    "        precip = item[5].to(device).long()\n",
    "        sun = item[6].to(device).long()\n",
    "        non_elec = item[7].to(device).long()\n",
    "        sunlight = item[8].to(device).long()\n",
    "\n",
    "        # Target\n",
    "        energy = item[1].to(device).float()\n",
    "        \n",
    "        target_mask = (num != 0)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(num, temp, wind_spd, humid, precip, sun, non_elec, sunlight)\n",
    "        \n",
    "        loss = criterion(output, energy)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss.append(loss.item())\n",
    "        \n",
    "        \n",
    "        # mask the output\n",
    "        output_mask = torch.masked_select(output, target_mask)\n",
    "        energy_mask = torch.masked_select(energy, target_mask)\n",
    "\n",
    "\n",
    "        energies.extend(energy_mask.view(-1).data.cpu().numpy())\n",
    "        outs.extend(output_mask.view(-1).data.cpu().numpy())\n",
    "\n",
    "#     train_auc = roc_auc_score(energies, outs)\n",
    "    train_loss = np.mean(train_loss)\n",
    "\n",
    "    energies = []\n",
    "    outs = []\n",
    "    val_loss = []\n",
    "\n",
    "    \n",
    "    # validation\n",
    "    model.eval()\n",
    "    for item in val_dataloader:\n",
    "        num = item[0].to(device).long()\n",
    "        temp = item[2].to(device).long()\n",
    "        wind_spd = item[3].to(device).long()\n",
    "        humid = item[4].to(device).long()\n",
    "        precip = item[5].to(device).long()\n",
    "        sun = item[6].to(device).long()\n",
    "        non_elec = item[7].to(device).long()\n",
    "        sunlight = item[8].to(device).long()\n",
    "        \n",
    "        # Target\n",
    "        energy = item[1].to(device).float()\n",
    "        \n",
    "        target_mask = (num != 0)\n",
    "        \n",
    "        output = model(num, temp, wind_spd, humid, precip, sun, non_elec, sunlight)\n",
    "\n",
    "        \n",
    "        ## mask the output\n",
    "        output = torch.masked_select(output, target_mask)\n",
    "        energy = torch.masked_select(energy, target_mask)\n",
    "        \n",
    "        \n",
    "        loss = criterion(output, energy)\n",
    "        val_loss.append(loss.item())\n",
    "\n",
    "        energies.extend(energy.view(-1).data.cpu().numpy())\n",
    "        outs.extend(output.view(-1).data.cpu().numpy())\n",
    "\n",
    "#     val_auc = roc_auc_score(energies, outs)\n",
    "    val_loss = np.mean(val_loss)\n",
    "\n",
    "    elapsed_time = time.time() - start_time \n",
    "\n",
    "#     return train_loss, train_auc, val_loss, val_auc, elapsed_time\n",
    "    return train_loss, val_loss, elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-27T13:20:32.827Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "#     train_loss, train_auc, val_loss, val_auc, elapsed_time = train_epoch(model, train_loader, val_loader, optimizer, criterion, device)\n",
    "    train_loss, val_loss, elapsed_time = train_epoch(model, train_loader, val_loader, optimizer, criterion, device)\n",
    "    \n",
    "#     print(\"epoch - {} train_loss - {:.4f} train_auc - {:.4f} val_loss - {:.4f} val_auc - {:.4f} time={:.2f}s\".format(epoch, train_loss, train_auc, val_loss, val_auc, elapsed_time))\n",
    "    print(\"epoch - {}  train_loss - {:.4f}  val_loss - {:.4f}  time={:.2f}s\".format(epoch, train_loss, val_loss, elapsed_time))\n",
    "#     logging.info(\"epoch - {} train_loss - {:.4f} train_auc - {:.4f} val_loss - {:.4f} val_auc - {:.4f} time={:.2f}s\".format(epoch, train_loss, train_auc, val_loss, val_auc, elapsed_time))\n",
    "    logging.info(\"epoch - {} train_loss - {:.4f}  val_loss - {:.4f}  time={:.2f}s\".format(epoch, train_loss, val_loss, elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:20:30.047015Z",
     "start_time": "2021-05-27T13:20:30.035587Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "#             correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
